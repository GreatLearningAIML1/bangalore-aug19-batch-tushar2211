{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Intro to Neural Networks_Project_6_Tushar.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Ep5TKkGUHDUt","colab_type":"text"},"source":["Data Description: Given a Bank customer, can we build a classifier that can determine whether they will leave or not using Neural networks?\n","\n","The dataset contains 10,000 sample points with 14 distinct features such as CustomerId, CreditScore, Geography, Gender, Age, Tenure, Balance etc. Know your data: https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling \n","\n","\n","Context:\n","Businesses like banks which provide service have to worry about problem of 'Churn' i.e. customers leaving and joining another service provider. It is important to understand which aspects of the service influence a\n","customer's decision in this regard. Management can concentrate efforts on improvement of service, keeping in mind these priorities.\n","\n","*    Steps and Milestones (100%):\n","\n","*    Setup Environment and Load Necessary Packages (5%)\n","\n","*   Data Preparation (40%)\n","*   Loading Data (5%)\n","*   Cleaning Data (10%)\n","*   Data Representation & Feature Engineering (If Any) (15%)\n","*   Creating Train and Validation Set (10%)\n","\n","*    Model Creation (30%)\n","*    Write & Configure Model (10%)\n","*    Compile Model (10%)\n","*    Build Model & Checking Summary (10%)\n","\n","*    Training and Evaluation (25%)\n","*    Run Multiple Experiments (10%)\n","*    Reason & Visualize Model Performance (5%)\n","*    Evaluate Model on Test Set (10%)\n","\n","Learning Outcomes:\n","*    Neural Networks for Predictive Analytics\n","*    Fine-tuning Model\n","*    Data Preparation\n","*    Feature Engineering\n","*    Visualization\n"," \n","\n","The points distribution for this case is as follows:\n","\n","1.   Read the data set\n","2.   Drop the columns which are unique for all users like IDs (2.5 points)\n","3.   Distinguish the feature and target set (2.5 points)\n","4.   Divide the data set into training and test sets ( 2.5 points)\n","5.   Normalize the train and test data (5 points)\n","6.   Initialize & build the model (10 points)\n","7.   Predict the results using 0.5 as a threshold (5 points)\n","8.   Print the Accuracy score and confusion matrix (2.5 points)\n"]},{"cell_type":"markdown","metadata":{"id":"K7p2ZdT_PCsZ","colab_type":"text"},"source":["Installing scikit learn 0.22"]},{"cell_type":"code","metadata":{"_kg_hide-output":true,"id":"H_l8d_XYHDU0","colab_type":"code","colab":{}},"source":["#!pip install scikit-learn==0.22.0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"X6MGZR-KHDVC","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import seaborn as sns\n","sns.set()\n","\n","import os\n","#print(os.listdir(\"../input\"))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"191e6ef1-260f-4f3e-822c-92397b6cc5df","_uuid":"a91e1f7964773655b9aaa13dd53676680ccfb47d","id":"XC0BrQI6HDVK","colab_type":"text"},"source":["###Data Preparation "]},{"cell_type":"markdown","metadata":{"id":"gqOIX8A9HDVM","colab_type":"text"},"source":["In this dataset, the information about a customer is given in columns 0 to 12 and the desired output is stored in the 13th (last column) of the dataset. Neither the customer ID, nor the Surname will matter in classification, therefore to reduce the dimensions, we will use columns 3 (CreditScore) inclusive through the 13th column for the analysis.\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"J7_Qwd7EIEyI","colab_type":"code","outputId":"6f409387-acf5-407c-8e4e-018e98cc7b51","executionInfo":{"status":"ok","timestamp":1581699971693,"user_tz":-330,"elapsed":1842,"user":{"displayName":"Tushar Saraf","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBsVKflt1O4j3WrSDN4_oLhCgLTQjjyjEEi2HI8ng=s64","userId":"06289736158237069082"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":218,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","id":"lDaRnRn2HDVO","colab_type":"code","outputId":"213be7ba-84c4-4a09-fdac-eb679cf74a93","executionInfo":{"status":"ok","timestamp":1581699971696,"user_tz":-330,"elapsed":1795,"user":{"displayName":"Tushar Saraf","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBsVKflt1O4j3WrSDN4_oLhCgLTQjjyjEEi2HI8ng=s64","userId":"06289736158237069082"}},"colab":{"base_uri":"https://localhost:8080/","height":253}},"source":["#importing the dataset\n","\n","bankdataset = pd.read_csv('/content/drive/My Drive/colab notebooks /Deep Learning and NN/bank.csv', index_col='RowNumber')\n","bankdataset.head()"],"execution_count":219,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CustomerId</th>\n","      <th>Surname</th>\n","      <th>CreditScore</th>\n","      <th>Geography</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Tenure</th>\n","      <th>Balance</th>\n","      <th>NumOfProducts</th>\n","      <th>HasCrCard</th>\n","      <th>IsActiveMember</th>\n","      <th>EstimatedSalary</th>\n","      <th>Exited</th>\n","    </tr>\n","    <tr>\n","      <th>RowNumber</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>15634602</td>\n","      <td>Hargrave</td>\n","      <td>619</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>42</td>\n","      <td>2</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>101348.88</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>15647311</td>\n","      <td>Hill</td>\n","      <td>608</td>\n","      <td>Spain</td>\n","      <td>Female</td>\n","      <td>41</td>\n","      <td>1</td>\n","      <td>83807.86</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>112542.58</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>15619304</td>\n","      <td>Onio</td>\n","      <td>502</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>42</td>\n","      <td>8</td>\n","      <td>159660.80</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113931.57</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>15701354</td>\n","      <td>Boni</td>\n","      <td>699</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>39</td>\n","      <td>1</td>\n","      <td>0.00</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>93826.63</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>15737888</td>\n","      <td>Mitchell</td>\n","      <td>850</td>\n","      <td>Spain</td>\n","      <td>Female</td>\n","      <td>43</td>\n","      <td>2</td>\n","      <td>125510.82</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>79084.10</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           CustomerId   Surname  ...  EstimatedSalary Exited\n","RowNumber                        ...                        \n","1            15634602  Hargrave  ...        101348.88      1\n","2            15647311      Hill  ...        112542.58      0\n","3            15619304      Onio  ...        113931.57      1\n","4            15701354      Boni  ...         93826.63      0\n","5            15737888  Mitchell  ...         79084.10      0\n","\n","[5 rows x 13 columns]"]},"metadata":{"tags":[]},"execution_count":219}]},{"cell_type":"code","metadata":{"id":"cTI1BBpAHDVX","colab_type":"code","outputId":"fb4d8141-f28c-468d-837d-53fca0783160","executionInfo":{"status":"ok","timestamp":1581699971699,"user_tz":-330,"elapsed":1772,"user":{"displayName":"Tushar Saraf","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBsVKflt1O4j3WrSDN4_oLhCgLTQjjyjEEi2HI8ng=s64","userId":"06289736158237069082"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["X_columns = bankdataset.columns.tolist()[2:12]\n","y_columns = bankdataset.columns.tolist()[-1:]\n","print(f'All columns: {bankdataset.columns.tolist()}')\n","print()\n","print(f'X values: {X_columns}')\n","print()\n","print(f'y values: {y_columns}')"],"execution_count":220,"outputs":[{"output_type":"stream","text":["All columns: ['CustomerId', 'Surname', 'CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited']\n","\n","X values: ['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n","\n","y values: ['Exited']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GUQicYofS7wo","colab_type":"text"},"source":["### Distinguishing the feature and target set in the data"]},{"cell_type":"code","metadata":{"id":"glyuMc8eHDVf","colab_type":"code","colab":{}},"source":["X = bankdataset[X_columns].values # All columns from Credit Score to Estimated Salary are taken as inputs\n","y = bankdataset[y_columns].values # desired output : whether customer exited or not ?"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"4a8358b6-15f3-447a-b7ca-84b1260be431","_uuid":"6ead7a5a9bd53033a6e2d72ee0d04c102ac62547","id":"DH_Wq-KyHDVo","colab_type":"code","colab":{}},"source":["# Encoding categorical (string based) data. Country: there are 3 options: France, Spain and Germany\n","# This will convert those strings into scalar values for analysis\n","#print(X[:8,1], '... will be encoded to: ')\n","from sklearn.preprocessing import LabelEncoder\n","label_X_country_encoder = LabelEncoder()\n","X[:,1] = label_X_country_encoder.fit_transform(X[:,1])\n","#print(X[:8,1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"50bb2761-7b6f-4612-978b-250bc52a7707","_uuid":"faf9d15f5568ebbaf1473a5341a7b38251d314c7","id":"frNbO2BKHDVw","colab_type":"code","colab":{}},"source":["# We will do the same thing for gender. this will be binary in this dataset\n","#print(X[:6,2], '... will be encoded to: ')\n","from sklearn.preprocessing import LabelEncoder\n","label_X_gender_encoder = LabelEncoder()\n","X[:,2] = label_X_gender_encoder.fit_transform(X[:,2])\n","#print(X[:6,2])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"6f5ab21e-bc4c-4d23-8124-b7fbde15295a","_uuid":"134720c31d216016bb6093571ca1cf08e49f0014","id":"fLP3G7GGHDV6","colab_type":"text"},"source":["Feature engineering is the most important aspect of creating an effective model. When dealing with categorical features, a common convention is to drop one of the one-hot encoded columns from each feature. \n","\n","First 3 columns represent the 3 countries(France, Spain and Germany) that constituted the \"country\" category variable. Now, observe that we essentially need only two columns: a 0 on two countries means that the country has to be the one variable which wasn't included, this will save us from the problem of using too many dimensions. This encoding can be achieved using the `drop='first'` option in the OneHotEncoder\n","\n","|1|0|0|-> |0|0|\n","|0|1|0|-> |1|0|\n","|0|1|0|-> |1|0|\n","|0|0|1|-> |0|1|\n","\n"]},{"cell_type":"markdown","metadata":{"_cell_guid":"19c34bde-4901-4116-81b5-0b2699cc8edc","_uuid":"baee254e5d7c52966a84ad53aa890b1b0c548436","id":"9xufwXuOHDV8","colab_type":"text"},"source":["Feature scaling is a method used to standardize the range of independent variables or features of data set. Since the range of values of raw data varies widely, in some machine learning algorithms, objective functions will not work properly without normalization. For example, many classifiers calculate the distance between two points by the Euclidean distance. If one of the features has a broad range of values, the distance will be governed by this particular feature. Therefore, the range of all features should be normalized so that each feature contributes approximately proportionately to the final distance.\n","\n","Another reason why feature scaling is applied is that gradient descent converges much faster with feature scaling than without it.["]},{"cell_type":"markdown","metadata":{"id":"A83MUtlNdAgs","colab_type":"text"},"source":["\n","Pipeline perform sequence of different transformations (find set of features, generate new features, select only some good features) of raw dataset before applying final estimator.\n","\n"]},{"cell_type":"code","metadata":{"id":"1wGpW9T8HDV_","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","\n","\n","pipeline = Pipeline(\n","    [('Categorizer', ColumnTransformer(\n","         [ # Gender\n","          (\"Gender Label encoder\", OneHotEncoder(categories='auto', drop='first'), [2]),\n","           # Geography\n","          (\"Geography One Hot\", OneHotEncoder(categories='auto', drop='first'), [1])\n","         ], remainder='passthrough', n_jobs=1)),\n","     # Standard Scaler for the classifier\n","    ('Normalizer', StandardScaler())\n","    ])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"7919a746-8eb9-4d5f-967f-d3e513320a93","_uuid":"9334654d846ed1d7c86b17c5cda8fd43ba193a62","id":"7E3VxfV0HDWH","colab_type":"code","colab":{}},"source":["X = pipeline.fit_transform(X)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"94dc69ae-e276-4ab8-9d42-89360e0f7ebb","_uuid":"b2608c0cb6e23abc91618d95ed9a06c1c0195c08","id":"JSEveToMHDWP","colab_type":"code","colab":{}},"source":["# Splitting the dataset into the Training and Testing set.\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"a96ac596-f07b-451c-a7aa-f98dc29bba81","_uuid":"00892464955a6ad79489335772ae7fbe2471ac2c","id":"6j_Y7kKOHDWW","colab_type":"code","outputId":"97650114-867a-4595-d433-9c8310e393a5","executionInfo":{"status":"ok","timestamp":1581699972174,"user_tz":-330,"elapsed":2075,"user":{"displayName":"Tushar Saraf","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBsVKflt1O4j3WrSDN4_oLhCgLTQjjyjEEi2HI8ng=s64","userId":"06289736158237069082"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["print(f'training shapes: {X_train.shape}, {y_train.shape}')\n","print(f'testing shapes: {X_test.shape}, {y_test.shape}')"],"execution_count":227,"outputs":[{"output_type":"stream","text":["training shapes: (8000, 11), (8000, 1)\n","testing shapes: (2000, 11), (2000, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"_cell_guid":"f8496b20-efff-48a4-8649-e6b60ac2e87b","_uuid":"219c2ec9230ef437b87cd0ec5ffe5eece2843874","id":"nHFzlGeWHDWh","colab_type":"text"},"source":["Nueral Network"]},{"cell_type":"code","metadata":{"_cell_guid":"9c95c5f3-117b-47ad-86e2-327cebb8db42","_uuid":"7cd3ececc193a95174a8d5efff01468336951441","id":"4lMZwOA-HDWi","colab_type":"code","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"477c2dd7-8267-4c0d-98d0-65483cfc47c0","_uuid":"842944c858018351df27d454c03fe3bc3c3498c7","id":"MudZNJudHDWq","colab_type":"code","colab":{}},"source":["# Initializing the ANN\n","classifier = Sequential()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"9a0c46ca-2e44-45bc-a48c-870f6aad0d0e","_uuid":"a9c849675833548a819cf26298658158e844de59","id":"jIBUPC-THDW0","colab_type":"text"},"source":["Determining the amount of nodes (dimensions) in the hidden layer can be any value between in the range of no. of dimensions, since we are going to implement / explore the deep learning, let's consider 6 nodes for the first layer.\n","\n","The breakdown of the inputs for the first layer is as follows:\n","\n","`units`: `6` nodes (number of nodes in hidden layer). Can think of this as number of nodes are in the next layer.\n","\n","`activiation`: `relu` becasue we are in an input layer. uses the ReLu activation function for the layer. This is equivalent to $max(0, W \\times x^T + b)$\n","\n","`input_dim`: `11` because we span 11 dimensions in our input layer. This is needed for the first added layer. The subsequent layers's input dimensions can be inferred using the previously added layer's output dimension. The next hidden layer will know what to expect.\n","\n","\n"]},{"cell_type":"code","metadata":{"_cell_guid":"74cbe4d8-517a-488d-92d0-71905549a062","_uuid":"d714ebc59f601dd833a0eaafc6ae9a81b9f9f2d8","id":"X3liGLd4HDW3","colab_type":"code","colab":{}},"source":["# This adds the input layer (by specifying input dimension) AND the first hidden layer (units)\n","classifier.add(Dense(3, activation = 'relu', input_shape = (X_train.shape[1], )))\n","#classifier.add(Dropout(rate=0.1)) "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"0c30399e-24f6-44ac-b468-13ad68813a03","_uuid":"47582c1198896d9c6276254440869f0ff685caa9","id":"8_AGcKBLHDW_","colab_type":"text"},"source":["Having Second hidden layer to this model to implement Deep Learning, which is an artificial Neural network with many layers. The second hidden layer also have 6 nodes."]},{"cell_type":"code","metadata":{"_cell_guid":"4b2e774c-dfae-425d-9814-791ba9385f54","_uuid":"4ee4b599740bccfd59166e6589f471c267bd3ba6","id":"nLTYhoEyHDXB","colab_type":"code","colab":{}},"source":["# Adding the second hidden layer\n","# Notice that we do not need to specify input dim. \n","classifier.add(Dense(3, activation = 'relu')) \n","#classifier.add(Dropout(rate=0.1)) "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"dcfa3079-f795-477b-a21c-e5cb3b6f0aef","_uuid":"9f0c01f7d7019c1a73cb3cfe05dc03104b07fed7","id":"EPciS8K2HDXK","colab_type":"text"},"source":["Output layer\n","#### The breakdown of the inputs for the output layer is as follows:\n","\n","*activiation*: **sigmoid** - output layer uses the Sigmoid activation function for $\\phi$. This is used instead of the ReLu function becasue it generates probabilities for the outcome and we want to know the probability that each customer leaves the bank.  \n","\n","`units`: `6` nodes (number of nodes in hidden layer). \n","\n","`input_dim`: `11` because we span 11 dimensions in our input layer. This is needed for the first added layer. The subsequent layers's input dimensions can be inferred using the previously added layer's output dimension. The next hidden layer will know what to expect.\n"]},{"cell_type":"code","metadata":{"_cell_guid":"85159374-4412-4d00-8120-04e2d3797d18","_uuid":"5e967723561562d1b402e531c51a9c505b3872cc","id":"Ck0M3Uc8HDXM","colab_type":"code","colab":{}},"source":["# Adding the output layer\n","# Notice that we do not need to specify input dim. \n","# we have an output of 1 node, which is the the desired dimensions of our output (stay with the bank or not)\n","# We use the sigmoid because we want probability outcomes\n","classifier.add(Dense(1, activation = 'sigmoid')) "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"aeca69c0-472e-4344-8523-d5c5a4893650","_uuid":"313cad84163d80c20e00eaac2d493c8eb50dab30","id":"Nu5ItB64HDXR","colab_type":"text"},"source":["Note : If the output needs to have more than two categories, then we will need to change \n","\n"," 1) the *units* parameter to match the desired category count\n"," \n"," 2) the *activation* field to **softmax**.  Basically a sigmoid function but applied to a dependent variable that has more than 2 categories."]},{"cell_type":"code","metadata":{"id":"oNfX4CZtHDXS","colab_type":"code","outputId":"d4b84537-f620-47e5-8466-45503f8e8526","executionInfo":{"status":"ok","timestamp":1581699972180,"user_tz":-330,"elapsed":1956,"user":{"displayName":"Tushar Saraf","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBsVKflt1O4j3WrSDN4_oLhCgLTQjjyjEEi2HI8ng=s64","userId":"06289736158237069082"}},"colab":{"base_uri":"https://localhost:8080/","height":260}},"source":["classifier.summary()"],"execution_count":233,"outputs":[{"output_type":"stream","text":["Model: \"sequential_10\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_28 (Dense)             (None, 3)                 36        \n","_________________________________________________________________\n","dense_29 (Dense)             (None, 3)                 12        \n","_________________________________________________________________\n","dense_30 (Dense)             (None, 1)                 4         \n","=================================================================\n","Total params: 52\n","Trainable params: 52\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"_cell_guid":"ba09a55b-572d-442c-9733-724600df8f9b","_uuid":"f220ac215b66c3f765d05ee1d1ac1ba51854bd5e","id":"jCdYD0o9HDXd","colab_type":"text"},"source":["Compiling the Neural Network\n","\n","Applying Stochastic Gradient descent on the whole Neural Network, tuning the individual weights on each neuron.\n","\n","The breakdown of the inputs for compiling is as follows:\n","\n","`optimizer`: `adam` The algorithm used to find the optimal set of weights in the neural networks, adam is a variation of Stochastic Gradient Descent.\n","\n","`loss`: `binary_crossentropy` This is the loss function used within adam. This should be the logarthmic loss. If our dependent (output variable) is `Binary`, it is `binary_crossentropy`. If `Categorical`, then it is called `categorical_crossentropy`\n","\n","`metrics`: `[accuracy]` The accuracy metrics which will be evaluated(minimized) by the model. Used as accuracy criteria to improve model performance."]},{"cell_type":"code","metadata":{"_cell_guid":"269e47c9-d147-4013-b704-3f74fd344315","_uuid":"827b3e0bb61ebad44f545d74b8bc021bbca6f1b2","id":"8gefvFEhHDXe","colab_type":"code","colab":{}},"source":["classifier.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"db47d3e6-fd4f-461d-aa7a-b743c6fcf260","_uuid":"d303bdd6aeb12b5ef9bd58d7a695ecfbc66bb131","id":"aFAff1XwHDXk","colab_type":"text"},"source":["The breakdown of the inputs for compiling is as follows:\n","\n","`X_train` The independent variable portion of the data which needs to be fitted with the model.\n","\n","`Y_train` The output portion of the data which the model needs to produce after fitting.\n","\n","`batch_size`:  How often we want to back-propogate the error values so that individual node weights can be adjusted. \n","\n","`epochs`: The number of times we want to run the entire test data over again to tune the weights. This is like the fuel of the algorithm. \n","\n","\n","`validation_split`: `0.2` The fraction of data to use for validation data. \n"]},{"cell_type":"code","metadata":{"_cell_guid":"5ab480db-3223-4577-87d9-27ab42572679","_uuid":"2373dff1ff229dbe72f41418035daf29049804df","id":"WAW3TMNFHDXl","colab_type":"code","outputId":"9f313820-e9e2-4c09-be9c-e7bf935d14d3","executionInfo":{"status":"ok","timestamp":1581699977945,"user_tz":-330,"elapsed":7683,"user":{"displayName":"Tushar Saraf","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBsVKflt1O4j3WrSDN4_oLhCgLTQjjyjEEi2HI8ng=s64","userId":"06289736158237069082"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["history = classifier.fit(X_train, y_train, batch_size=1000, epochs=200, validation_split=0.1, verbose=2)"],"execution_count":235,"outputs":[{"output_type":"stream","text":["Train on 7200 samples, validate on 800 samples\n","Epoch 1/200\n"," - 1s - loss: 1.0059 - acc: 0.3125 - val_loss: 0.9882 - val_acc: 0.3162\n","Epoch 2/200\n"," - 0s - loss: 0.9794 - acc: 0.3181 - val_loss: 0.9615 - val_acc: 0.3275\n","Epoch 3/200\n"," - 0s - loss: 0.9535 - acc: 0.3264 - val_loss: 0.9363 - val_acc: 0.3363\n","Epoch 4/200\n"," - 0s - loss: 0.9290 - acc: 0.3390 - val_loss: 0.9127 - val_acc: 0.3500\n","Epoch 5/200\n"," - 0s - loss: 0.9065 - acc: 0.3485 - val_loss: 0.8910 - val_acc: 0.3638\n","Epoch 6/200\n"," - 0s - loss: 0.8854 - acc: 0.3578 - val_loss: 0.8711 - val_acc: 0.3738\n","Epoch 7/200\n"," - 0s - loss: 0.8663 - acc: 0.3654 - val_loss: 0.8527 - val_acc: 0.3812\n","Epoch 8/200\n"," - 0s - loss: 0.8486 - acc: 0.3767 - val_loss: 0.8356 - val_acc: 0.3938\n","Epoch 9/200\n"," - 0s - loss: 0.8322 - acc: 0.3865 - val_loss: 0.8198 - val_acc: 0.3963\n","Epoch 10/200\n"," - 0s - loss: 0.8167 - acc: 0.4006 - val_loss: 0.8052 - val_acc: 0.4062\n","Epoch 11/200\n"," - 0s - loss: 0.8025 - acc: 0.4142 - val_loss: 0.7915 - val_acc: 0.4200\n","Epoch 12/200\n"," - 0s - loss: 0.7894 - acc: 0.4265 - val_loss: 0.7787 - val_acc: 0.4313\n","Epoch 13/200\n"," - 0s - loss: 0.7769 - acc: 0.4394 - val_loss: 0.7670 - val_acc: 0.4412\n","Epoch 14/200\n"," - 0s - loss: 0.7654 - acc: 0.4544 - val_loss: 0.7559 - val_acc: 0.4638\n","Epoch 15/200\n"," - 0s - loss: 0.7547 - acc: 0.4676 - val_loss: 0.7454 - val_acc: 0.4850\n","Epoch 16/200\n"," - 0s - loss: 0.7443 - acc: 0.4865 - val_loss: 0.7355 - val_acc: 0.5050\n","Epoch 17/200\n"," - 0s - loss: 0.7346 - acc: 0.5019 - val_loss: 0.7260 - val_acc: 0.5188\n","Epoch 18/200\n"," - 0s - loss: 0.7254 - acc: 0.5176 - val_loss: 0.7172 - val_acc: 0.5362\n","Epoch 19/200\n"," - 0s - loss: 0.7165 - acc: 0.5407 - val_loss: 0.7088 - val_acc: 0.5512\n","Epoch 20/200\n"," - 0s - loss: 0.7082 - acc: 0.5626 - val_loss: 0.7007 - val_acc: 0.5700\n","Epoch 21/200\n"," - 0s - loss: 0.7000 - acc: 0.5819 - val_loss: 0.6929 - val_acc: 0.5975\n","Epoch 22/200\n"," - 0s - loss: 0.6923 - acc: 0.6058 - val_loss: 0.6855 - val_acc: 0.6112\n","Epoch 23/200\n"," - 0s - loss: 0.6849 - acc: 0.6253 - val_loss: 0.6784 - val_acc: 0.6300\n","Epoch 24/200\n"," - 0s - loss: 0.6778 - acc: 0.6436 - val_loss: 0.6715 - val_acc: 0.6562\n","Epoch 25/200\n"," - 0s - loss: 0.6709 - acc: 0.6574 - val_loss: 0.6648 - val_acc: 0.6700\n","Epoch 26/200\n"," - 0s - loss: 0.6642 - acc: 0.6715 - val_loss: 0.6585 - val_acc: 0.6875\n","Epoch 27/200\n"," - 0s - loss: 0.6576 - acc: 0.6840 - val_loss: 0.6522 - val_acc: 0.7025\n","Epoch 28/200\n"," - 0s - loss: 0.6511 - acc: 0.7004 - val_loss: 0.6459 - val_acc: 0.7200\n","Epoch 29/200\n"," - 0s - loss: 0.6446 - acc: 0.7147 - val_loss: 0.6398 - val_acc: 0.7275\n","Epoch 30/200\n"," - 0s - loss: 0.6383 - acc: 0.7254 - val_loss: 0.6338 - val_acc: 0.7425\n","Epoch 31/200\n"," - 0s - loss: 0.6322 - acc: 0.7350 - val_loss: 0.6279 - val_acc: 0.7563\n","Epoch 32/200\n"," - 0s - loss: 0.6261 - acc: 0.7446 - val_loss: 0.6222 - val_acc: 0.7625\n","Epoch 33/200\n"," - 0s - loss: 0.6203 - acc: 0.7544 - val_loss: 0.6164 - val_acc: 0.7625\n","Epoch 34/200\n"," - 0s - loss: 0.6143 - acc: 0.7631 - val_loss: 0.6107 - val_acc: 0.7700\n","Epoch 35/200\n"," - 0s - loss: 0.6082 - acc: 0.7711 - val_loss: 0.6049 - val_acc: 0.7775\n","Epoch 36/200\n"," - 0s - loss: 0.6022 - acc: 0.7769 - val_loss: 0.5993 - val_acc: 0.7850\n","Epoch 37/200\n"," - 0s - loss: 0.5962 - acc: 0.7844 - val_loss: 0.5935 - val_acc: 0.7912\n","Epoch 38/200\n"," - 0s - loss: 0.5903 - acc: 0.7885 - val_loss: 0.5878 - val_acc: 0.7950\n","Epoch 39/200\n"," - 0s - loss: 0.5845 - acc: 0.7928 - val_loss: 0.5823 - val_acc: 0.7950\n","Epoch 40/200\n"," - 0s - loss: 0.5789 - acc: 0.7949 - val_loss: 0.5768 - val_acc: 0.7950\n","Epoch 41/200\n"," - 0s - loss: 0.5735 - acc: 0.7958 - val_loss: 0.5716 - val_acc: 0.7950\n","Epoch 42/200\n"," - 0s - loss: 0.5683 - acc: 0.7960 - val_loss: 0.5666 - val_acc: 0.7950\n","Epoch 43/200\n"," - 0s - loss: 0.5632 - acc: 0.7961 - val_loss: 0.5618 - val_acc: 0.7950\n","Epoch 44/200\n"," - 0s - loss: 0.5584 - acc: 0.7961 - val_loss: 0.5571 - val_acc: 0.7950\n","Epoch 45/200\n"," - 0s - loss: 0.5538 - acc: 0.7961 - val_loss: 0.5527 - val_acc: 0.7950\n","Epoch 46/200\n"," - 0s - loss: 0.5495 - acc: 0.7961 - val_loss: 0.5486 - val_acc: 0.7950\n","Epoch 47/200\n"," - 0s - loss: 0.5455 - acc: 0.7961 - val_loss: 0.5447 - val_acc: 0.7950\n","Epoch 48/200\n"," - 0s - loss: 0.5418 - acc: 0.7961 - val_loss: 0.5411 - val_acc: 0.7950\n","Epoch 49/200\n"," - 0s - loss: 0.5383 - acc: 0.7961 - val_loss: 0.5375 - val_acc: 0.7950\n","Epoch 50/200\n"," - 0s - loss: 0.5349 - acc: 0.7961 - val_loss: 0.5341 - val_acc: 0.7950\n","Epoch 51/200\n"," - 0s - loss: 0.5317 - acc: 0.7961 - val_loss: 0.5310 - val_acc: 0.7950\n","Epoch 52/200\n"," - 0s - loss: 0.5288 - acc: 0.7961 - val_loss: 0.5280 - val_acc: 0.7950\n","Epoch 53/200\n"," - 0s - loss: 0.5260 - acc: 0.7961 - val_loss: 0.5251 - val_acc: 0.7950\n","Epoch 54/200\n"," - 0s - loss: 0.5233 - acc: 0.7961 - val_loss: 0.5224 - val_acc: 0.7950\n","Epoch 55/200\n"," - 0s - loss: 0.5209 - acc: 0.7961 - val_loss: 0.5199 - val_acc: 0.7950\n","Epoch 56/200\n"," - 0s - loss: 0.5185 - acc: 0.7961 - val_loss: 0.5175 - val_acc: 0.7950\n","Epoch 57/200\n"," - 0s - loss: 0.5164 - acc: 0.7961 - val_loss: 0.5152 - val_acc: 0.7950\n","Epoch 58/200\n"," - 0s - loss: 0.5143 - acc: 0.7961 - val_loss: 0.5131 - val_acc: 0.7950\n","Epoch 59/200\n"," - 0s - loss: 0.5123 - acc: 0.7961 - val_loss: 0.5111 - val_acc: 0.7950\n","Epoch 60/200\n"," - 0s - loss: 0.5105 - acc: 0.7961 - val_loss: 0.5091 - val_acc: 0.7950\n","Epoch 61/200\n"," - 0s - loss: 0.5088 - acc: 0.7961 - val_loss: 0.5073 - val_acc: 0.7950\n","Epoch 62/200\n"," - 0s - loss: 0.5070 - acc: 0.7961 - val_loss: 0.5055 - val_acc: 0.7950\n","Epoch 63/200\n"," - 0s - loss: 0.5054 - acc: 0.7961 - val_loss: 0.5038 - val_acc: 0.7950\n","Epoch 64/200\n"," - 0s - loss: 0.5039 - acc: 0.7961 - val_loss: 0.5022 - val_acc: 0.7950\n","Epoch 65/200\n"," - 0s - loss: 0.5024 - acc: 0.7961 - val_loss: 0.5006 - val_acc: 0.7950\n","Epoch 66/200\n"," - 0s - loss: 0.5010 - acc: 0.7961 - val_loss: 0.4992 - val_acc: 0.7950\n","Epoch 67/200\n"," - 0s - loss: 0.4997 - acc: 0.7961 - val_loss: 0.4978 - val_acc: 0.7950\n","Epoch 68/200\n"," - 0s - loss: 0.4984 - acc: 0.7961 - val_loss: 0.4965 - val_acc: 0.7950\n","Epoch 69/200\n"," - 0s - loss: 0.4972 - acc: 0.7961 - val_loss: 0.4952 - val_acc: 0.7950\n","Epoch 70/200\n"," - 0s - loss: 0.4960 - acc: 0.7961 - val_loss: 0.4939 - val_acc: 0.7950\n","Epoch 71/200\n"," - 0s - loss: 0.4949 - acc: 0.7961 - val_loss: 0.4927 - val_acc: 0.7950\n","Epoch 72/200\n"," - 0s - loss: 0.4938 - acc: 0.7961 - val_loss: 0.4915 - val_acc: 0.7950\n","Epoch 73/200\n"," - 0s - loss: 0.4927 - acc: 0.7961 - val_loss: 0.4904 - val_acc: 0.7950\n","Epoch 74/200\n"," - 0s - loss: 0.4917 - acc: 0.7961 - val_loss: 0.4893 - val_acc: 0.7950\n","Epoch 75/200\n"," - 0s - loss: 0.4907 - acc: 0.7961 - val_loss: 0.4883 - val_acc: 0.7950\n","Epoch 76/200\n"," - 0s - loss: 0.4898 - acc: 0.7961 - val_loss: 0.4873 - val_acc: 0.7950\n","Epoch 77/200\n"," - 0s - loss: 0.4889 - acc: 0.7961 - val_loss: 0.4864 - val_acc: 0.7950\n","Epoch 78/200\n"," - 0s - loss: 0.4880 - acc: 0.7961 - val_loss: 0.4855 - val_acc: 0.7950\n","Epoch 79/200\n"," - 0s - loss: 0.4871 - acc: 0.7961 - val_loss: 0.4846 - val_acc: 0.7950\n","Epoch 80/200\n"," - 0s - loss: 0.4863 - acc: 0.7961 - val_loss: 0.4837 - val_acc: 0.7950\n","Epoch 81/200\n"," - 0s - loss: 0.4854 - acc: 0.7961 - val_loss: 0.4829 - val_acc: 0.7950\n","Epoch 82/200\n"," - 0s - loss: 0.4847 - acc: 0.7961 - val_loss: 0.4822 - val_acc: 0.7950\n","Epoch 83/200\n"," - 0s - loss: 0.4839 - acc: 0.7961 - val_loss: 0.4815 - val_acc: 0.7950\n","Epoch 84/200\n"," - 0s - loss: 0.4832 - acc: 0.7961 - val_loss: 0.4808 - val_acc: 0.7950\n","Epoch 85/200\n"," - 0s - loss: 0.4825 - acc: 0.7961 - val_loss: 0.4801 - val_acc: 0.7950\n","Epoch 86/200\n"," - 0s - loss: 0.4818 - acc: 0.7961 - val_loss: 0.4795 - val_acc: 0.7950\n","Epoch 87/200\n"," - 0s - loss: 0.4811 - acc: 0.7961 - val_loss: 0.4789 - val_acc: 0.7950\n","Epoch 88/200\n"," - 0s - loss: 0.4804 - acc: 0.7961 - val_loss: 0.4782 - val_acc: 0.7950\n","Epoch 89/200\n"," - 0s - loss: 0.4798 - acc: 0.7961 - val_loss: 0.4776 - val_acc: 0.7950\n","Epoch 90/200\n"," - 0s - loss: 0.4791 - acc: 0.7961 - val_loss: 0.4770 - val_acc: 0.7950\n","Epoch 91/200\n"," - 0s - loss: 0.4784 - acc: 0.7961 - val_loss: 0.4764 - val_acc: 0.7950\n","Epoch 92/200\n"," - 0s - loss: 0.4778 - acc: 0.7961 - val_loss: 0.4758 - val_acc: 0.7950\n","Epoch 93/200\n"," - 0s - loss: 0.4771 - acc: 0.7961 - val_loss: 0.4753 - val_acc: 0.7950\n","Epoch 94/200\n"," - 0s - loss: 0.4765 - acc: 0.7961 - val_loss: 0.4747 - val_acc: 0.7950\n","Epoch 95/200\n"," - 0s - loss: 0.4758 - acc: 0.7961 - val_loss: 0.4742 - val_acc: 0.7950\n","Epoch 96/200\n"," - 0s - loss: 0.4752 - acc: 0.7961 - val_loss: 0.4736 - val_acc: 0.7950\n","Epoch 97/200\n"," - 0s - loss: 0.4746 - acc: 0.7961 - val_loss: 0.4730 - val_acc: 0.7950\n","Epoch 98/200\n"," - 0s - loss: 0.4740 - acc: 0.7961 - val_loss: 0.4725 - val_acc: 0.7950\n","Epoch 99/200\n"," - 0s - loss: 0.4733 - acc: 0.7961 - val_loss: 0.4719 - val_acc: 0.7950\n","Epoch 100/200\n"," - 0s - loss: 0.4727 - acc: 0.7961 - val_loss: 0.4714 - val_acc: 0.7950\n","Epoch 101/200\n"," - 0s - loss: 0.4721 - acc: 0.7961 - val_loss: 0.4708 - val_acc: 0.7950\n","Epoch 102/200\n"," - 0s - loss: 0.4715 - acc: 0.7961 - val_loss: 0.4702 - val_acc: 0.7950\n","Epoch 103/200\n"," - 0s - loss: 0.4709 - acc: 0.7961 - val_loss: 0.4697 - val_acc: 0.7950\n","Epoch 104/200\n"," - 0s - loss: 0.4703 - acc: 0.7961 - val_loss: 0.4692 - val_acc: 0.7950\n","Epoch 105/200\n"," - 0s - loss: 0.4697 - acc: 0.7961 - val_loss: 0.4687 - val_acc: 0.7950\n","Epoch 106/200\n"," - 0s - loss: 0.4692 - acc: 0.7961 - val_loss: 0.4682 - val_acc: 0.7950\n","Epoch 107/200\n"," - 0s - loss: 0.4686 - acc: 0.7961 - val_loss: 0.4676 - val_acc: 0.7950\n","Epoch 108/200\n"," - 0s - loss: 0.4680 - acc: 0.7961 - val_loss: 0.4671 - val_acc: 0.7950\n","Epoch 109/200\n"," - 0s - loss: 0.4674 - acc: 0.7961 - val_loss: 0.4665 - val_acc: 0.7950\n","Epoch 110/200\n"," - 0s - loss: 0.4668 - acc: 0.7961 - val_loss: 0.4659 - val_acc: 0.7950\n","Epoch 111/200\n"," - 0s - loss: 0.4662 - acc: 0.7961 - val_loss: 0.4654 - val_acc: 0.7950\n","Epoch 112/200\n"," - 0s - loss: 0.4656 - acc: 0.7961 - val_loss: 0.4648 - val_acc: 0.7950\n","Epoch 113/200\n"," - 0s - loss: 0.4651 - acc: 0.7961 - val_loss: 0.4642 - val_acc: 0.7950\n","Epoch 114/200\n"," - 0s - loss: 0.4645 - acc: 0.7961 - val_loss: 0.4637 - val_acc: 0.7950\n","Epoch 115/200\n"," - 0s - loss: 0.4640 - acc: 0.7961 - val_loss: 0.4631 - val_acc: 0.7950\n","Epoch 116/200\n"," - 0s - loss: 0.4634 - acc: 0.7961 - val_loss: 0.4625 - val_acc: 0.7950\n","Epoch 117/200\n"," - 0s - loss: 0.4629 - acc: 0.7961 - val_loss: 0.4620 - val_acc: 0.7950\n","Epoch 118/200\n"," - 0s - loss: 0.4623 - acc: 0.7961 - val_loss: 0.4614 - val_acc: 0.7950\n","Epoch 119/200\n"," - 0s - loss: 0.4618 - acc: 0.7961 - val_loss: 0.4609 - val_acc: 0.7950\n","Epoch 120/200\n"," - 0s - loss: 0.4613 - acc: 0.7961 - val_loss: 0.4604 - val_acc: 0.7950\n","Epoch 121/200\n"," - 0s - loss: 0.4608 - acc: 0.7961 - val_loss: 0.4598 - val_acc: 0.7950\n","Epoch 122/200\n"," - 0s - loss: 0.4603 - acc: 0.7961 - val_loss: 0.4592 - val_acc: 0.7950\n","Epoch 123/200\n"," - 0s - loss: 0.4598 - acc: 0.7961 - val_loss: 0.4587 - val_acc: 0.7950\n","Epoch 124/200\n"," - 0s - loss: 0.4593 - acc: 0.7961 - val_loss: 0.4581 - val_acc: 0.7950\n","Epoch 125/200\n"," - 0s - loss: 0.4588 - acc: 0.7961 - val_loss: 0.4576 - val_acc: 0.7950\n","Epoch 126/200\n"," - 0s - loss: 0.4582 - acc: 0.7961 - val_loss: 0.4571 - val_acc: 0.7950\n","Epoch 127/200\n"," - 0s - loss: 0.4578 - acc: 0.7961 - val_loss: 0.4565 - val_acc: 0.7950\n","Epoch 128/200\n"," - 0s - loss: 0.4572 - acc: 0.7961 - val_loss: 0.4560 - val_acc: 0.7950\n","Epoch 129/200\n"," - 0s - loss: 0.4568 - acc: 0.7961 - val_loss: 0.4555 - val_acc: 0.7950\n","Epoch 130/200\n"," - 0s - loss: 0.4563 - acc: 0.7961 - val_loss: 0.4549 - val_acc: 0.7950\n","Epoch 131/200\n"," - 0s - loss: 0.4558 - acc: 0.7961 - val_loss: 0.4544 - val_acc: 0.7950\n","Epoch 132/200\n"," - 0s - loss: 0.4554 - acc: 0.7961 - val_loss: 0.4539 - val_acc: 0.7950\n","Epoch 133/200\n"," - 0s - loss: 0.4549 - acc: 0.7961 - val_loss: 0.4534 - val_acc: 0.7950\n","Epoch 134/200\n"," - 0s - loss: 0.4544 - acc: 0.7961 - val_loss: 0.4529 - val_acc: 0.7950\n","Epoch 135/200\n"," - 0s - loss: 0.4540 - acc: 0.7961 - val_loss: 0.4524 - val_acc: 0.7950\n","Epoch 136/200\n"," - 0s - loss: 0.4535 - acc: 0.7961 - val_loss: 0.4519 - val_acc: 0.7950\n","Epoch 137/200\n"," - 0s - loss: 0.4530 - acc: 0.7961 - val_loss: 0.4514 - val_acc: 0.7950\n","Epoch 138/200\n"," - 0s - loss: 0.4526 - acc: 0.7961 - val_loss: 0.4509 - val_acc: 0.7950\n","Epoch 139/200\n"," - 0s - loss: 0.4522 - acc: 0.7961 - val_loss: 0.4505 - val_acc: 0.7950\n","Epoch 140/200\n"," - 0s - loss: 0.4518 - acc: 0.7961 - val_loss: 0.4500 - val_acc: 0.7950\n","Epoch 141/200\n"," - 0s - loss: 0.4514 - acc: 0.7961 - val_loss: 0.4496 - val_acc: 0.7950\n","Epoch 142/200\n"," - 0s - loss: 0.4510 - acc: 0.7961 - val_loss: 0.4492 - val_acc: 0.7950\n","Epoch 143/200\n"," - 0s - loss: 0.4506 - acc: 0.7961 - val_loss: 0.4487 - val_acc: 0.7950\n","Epoch 144/200\n"," - 0s - loss: 0.4502 - acc: 0.7961 - val_loss: 0.4483 - val_acc: 0.7950\n","Epoch 145/200\n"," - 0s - loss: 0.4498 - acc: 0.7961 - val_loss: 0.4479 - val_acc: 0.7950\n","Epoch 146/200\n"," - 0s - loss: 0.4495 - acc: 0.7961 - val_loss: 0.4475 - val_acc: 0.7950\n","Epoch 147/200\n"," - 0s - loss: 0.4491 - acc: 0.7961 - val_loss: 0.4471 - val_acc: 0.7950\n","Epoch 148/200\n"," - 0s - loss: 0.4488 - acc: 0.7961 - val_loss: 0.4467 - val_acc: 0.7950\n","Epoch 149/200\n"," - 0s - loss: 0.4484 - acc: 0.7961 - val_loss: 0.4463 - val_acc: 0.7950\n","Epoch 150/200\n"," - 0s - loss: 0.4480 - acc: 0.7961 - val_loss: 0.4459 - val_acc: 0.7950\n","Epoch 151/200\n"," - 0s - loss: 0.4477 - acc: 0.7961 - val_loss: 0.4454 - val_acc: 0.7950\n","Epoch 152/200\n"," - 0s - loss: 0.4474 - acc: 0.7961 - val_loss: 0.4450 - val_acc: 0.7950\n","Epoch 153/200\n"," - 0s - loss: 0.4470 - acc: 0.7961 - val_loss: 0.4445 - val_acc: 0.7950\n","Epoch 154/200\n"," - 0s - loss: 0.4467 - acc: 0.7961 - val_loss: 0.4442 - val_acc: 0.7950\n","Epoch 155/200\n"," - 0s - loss: 0.4464 - acc: 0.7961 - val_loss: 0.4438 - val_acc: 0.7950\n","Epoch 156/200\n"," - 0s - loss: 0.4461 - acc: 0.7961 - val_loss: 0.4434 - val_acc: 0.7950\n","Epoch 157/200\n"," - 0s - loss: 0.4458 - acc: 0.7961 - val_loss: 0.4431 - val_acc: 0.7950\n","Epoch 158/200\n"," - 0s - loss: 0.4455 - acc: 0.7961 - val_loss: 0.4428 - val_acc: 0.7950\n","Epoch 159/200\n"," - 0s - loss: 0.4452 - acc: 0.7961 - val_loss: 0.4425 - val_acc: 0.7950\n","Epoch 160/200\n"," - 0s - loss: 0.4449 - acc: 0.7961 - val_loss: 0.4422 - val_acc: 0.7950\n","Epoch 161/200\n"," - 0s - loss: 0.4447 - acc: 0.7961 - val_loss: 0.4418 - val_acc: 0.7950\n","Epoch 162/200\n"," - 0s - loss: 0.4444 - acc: 0.7961 - val_loss: 0.4416 - val_acc: 0.7950\n","Epoch 163/200\n"," - 0s - loss: 0.4441 - acc: 0.7961 - val_loss: 0.4413 - val_acc: 0.7950\n","Epoch 164/200\n"," - 0s - loss: 0.4438 - acc: 0.7961 - val_loss: 0.4410 - val_acc: 0.7950\n","Epoch 165/200\n"," - 0s - loss: 0.4436 - acc: 0.7961 - val_loss: 0.4407 - val_acc: 0.7950\n","Epoch 166/200\n"," - 0s - loss: 0.4433 - acc: 0.7961 - val_loss: 0.4404 - val_acc: 0.7950\n","Epoch 167/200\n"," - 0s - loss: 0.4431 - acc: 0.7961 - val_loss: 0.4401 - val_acc: 0.7950\n","Epoch 168/200\n"," - 0s - loss: 0.4428 - acc: 0.7961 - val_loss: 0.4398 - val_acc: 0.7950\n","Epoch 169/200\n"," - 0s - loss: 0.4426 - acc: 0.7961 - val_loss: 0.4394 - val_acc: 0.7950\n","Epoch 170/200\n"," - 0s - loss: 0.4424 - acc: 0.7961 - val_loss: 0.4391 - val_acc: 0.7950\n","Epoch 171/200\n"," - 0s - loss: 0.4422 - acc: 0.7961 - val_loss: 0.4388 - val_acc: 0.7950\n","Epoch 172/200\n"," - 0s - loss: 0.4420 - acc: 0.7961 - val_loss: 0.4385 - val_acc: 0.7950\n","Epoch 173/200\n"," - 0s - loss: 0.4417 - acc: 0.7961 - val_loss: 0.4383 - val_acc: 0.7950\n","Epoch 174/200\n"," - 0s - loss: 0.4416 - acc: 0.7961 - val_loss: 0.4381 - val_acc: 0.7950\n","Epoch 175/200\n"," - 0s - loss: 0.4414 - acc: 0.7961 - val_loss: 0.4378 - val_acc: 0.7950\n","Epoch 176/200\n"," - 0s - loss: 0.4412 - acc: 0.7961 - val_loss: 0.4376 - val_acc: 0.7950\n","Epoch 177/200\n"," - 0s - loss: 0.4410 - acc: 0.7961 - val_loss: 0.4373 - val_acc: 0.7950\n","Epoch 178/200\n"," - 0s - loss: 0.4408 - acc: 0.7961 - val_loss: 0.4370 - val_acc: 0.7950\n","Epoch 179/200\n"," - 0s - loss: 0.4406 - acc: 0.7961 - val_loss: 0.4367 - val_acc: 0.7950\n","Epoch 180/200\n"," - 0s - loss: 0.4404 - acc: 0.7961 - val_loss: 0.4365 - val_acc: 0.7950\n","Epoch 181/200\n"," - 0s - loss: 0.4402 - acc: 0.7961 - val_loss: 0.4362 - val_acc: 0.7950\n","Epoch 182/200\n"," - 0s - loss: 0.4400 - acc: 0.7961 - val_loss: 0.4360 - val_acc: 0.7950\n","Epoch 183/200\n"," - 0s - loss: 0.4399 - acc: 0.7961 - val_loss: 0.4358 - val_acc: 0.7950\n","Epoch 184/200\n"," - 0s - loss: 0.4397 - acc: 0.7961 - val_loss: 0.4356 - val_acc: 0.7950\n","Epoch 185/200\n"," - 0s - loss: 0.4395 - acc: 0.7961 - val_loss: 0.4353 - val_acc: 0.7950\n","Epoch 186/200\n"," - 0s - loss: 0.4393 - acc: 0.7961 - val_loss: 0.4350 - val_acc: 0.7950\n","Epoch 187/200\n"," - 0s - loss: 0.4392 - acc: 0.7961 - val_loss: 0.4348 - val_acc: 0.7950\n","Epoch 188/200\n"," - 0s - loss: 0.4390 - acc: 0.7961 - val_loss: 0.4345 - val_acc: 0.7950\n","Epoch 189/200\n"," - 0s - loss: 0.4388 - acc: 0.7961 - val_loss: 0.4343 - val_acc: 0.7950\n","Epoch 190/200\n"," - 0s - loss: 0.4386 - acc: 0.7961 - val_loss: 0.4340 - val_acc: 0.7950\n","Epoch 191/200\n"," - 0s - loss: 0.4385 - acc: 0.7961 - val_loss: 0.4338 - val_acc: 0.7950\n","Epoch 192/200\n"," - 0s - loss: 0.4383 - acc: 0.7961 - val_loss: 0.4336 - val_acc: 0.7950\n","Epoch 193/200\n"," - 0s - loss: 0.4381 - acc: 0.7961 - val_loss: 0.4334 - val_acc: 0.7950\n","Epoch 194/200\n"," - 0s - loss: 0.4380 - acc: 0.7961 - val_loss: 0.4332 - val_acc: 0.7950\n","Epoch 195/200\n"," - 0s - loss: 0.4379 - acc: 0.7961 - val_loss: 0.4330 - val_acc: 0.7950\n","Epoch 196/200\n"," - 0s - loss: 0.4377 - acc: 0.7961 - val_loss: 0.4328 - val_acc: 0.7950\n","Epoch 197/200\n"," - 0s - loss: 0.4376 - acc: 0.7961 - val_loss: 0.4327 - val_acc: 0.7950\n","Epoch 198/200\n"," - 0s - loss: 0.4375 - acc: 0.7961 - val_loss: 0.4325 - val_acc: 0.7950\n","Epoch 199/200\n"," - 0s - loss: 0.4373 - acc: 0.7961 - val_loss: 0.4325 - val_acc: 0.7950\n","Epoch 200/200\n"," - 0s - loss: 0.4372 - acc: 0.7961 - val_loss: 0.4322 - val_acc: 0.7950\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"_cell_guid":"e4bc3339-634c-4343-9bf3-e5fe86be5b21","_uuid":"05146ba8ae06c97f679d19c7785e34fc301a4146","id":"Jidl8_amHDXq","colab_type":"text"},"source":["The output network should converge to an accuracy of around 79%\n","\n","\n","Testing the NN\n","Predicting the Test Set results\n","\n","This shows the probability of a customer leaving given the testing data. Each row in X_test corresponds to a row in Y_test"]},{"cell_type":"code","metadata":{"id":"KhY3afHoHDXs","colab_type":"code","outputId":"80117f6d-645f-47dc-94f4-247964f9db75","executionInfo":{"status":"ok","timestamp":1581699978641,"user_tz":-330,"elapsed":8349,"user":{"displayName":"Tushar Saraf","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBsVKflt1O4j3WrSDN4_oLhCgLTQjjyjEEi2HI8ng=s64","userId":"06289736158237069082"}},"colab":{"base_uri":"https://localhost:8080/","height":301}},"source":["plt.plot(np.array(history.history['acc']) * 100)\n","plt.plot(np.array(history.history['val_acc']) * 100)\n","plt.ylabel('accuracy')\n","plt.xlabel('epochs')\n","plt.legend(['train', 'validation'])\n","plt.title('Accuracy over epochs')\n","plt.show()"],"execution_count":236,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAEcCAYAAAAoSqjDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSpoAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"_cell_guid":"b8414c74-b1d9-4171-9f01-6b1b2d642c0e","_uuid":"c6f9748ac1c12e6786615c664e4fae7d34238dd5","id":"_ogeZsxrHDXw","colab_type":"code","outputId":"a3f0a43b-75a0-4120-d5fc-36e38e651682","executionInfo":{"status":"ok","timestamp":1581699978648,"user_tz":-330,"elapsed":8336,"user":{"displayName":"Tushar Saraf","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBsVKflt1O4j3WrSDN4_oLhCgLTQjjyjEEi2HI8ng=s64","userId":"06289736158237069082"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["y_pred = classifier.predict(X_test)\n","print(y_pred[:5])"],"execution_count":237,"outputs":[{"output_type":"stream","text":["[[0.26004136]\n"," [0.31866312]\n"," [0.21305808]\n"," [0.08393621]\n"," [0.20702416]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"_cell_guid":"dadcf0b3-ec7d-496a-b9ee-733f74d147a0","_uuid":"d114142f9b8006cd824e5321d973b410cf1f8242","id":"P5uZk1KgHDX2","colab_type":"text"},"source":["Predict the results using 0.5 as a threshold."]},{"cell_type":"code","metadata":{"id":"VcA0jAroHDX4","colab_type":"code","outputId":"ae70ebd7-3db2-41c1-dc09-2c3baf399f32","executionInfo":{"status":"ok","timestamp":1581699978650,"user_tz":-330,"elapsed":8294,"user":{"displayName":"Tushar Saraf","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBsVKflt1O4j3WrSDN4_oLhCgLTQjjyjEEi2HI8ng=s64","userId":"06289736158237069082"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["y_pred = (y_pred > 0.5).astype(int)\n","print(y_pred[:5])"],"execution_count":238,"outputs":[{"output_type":"stream","text":["[[0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"_cell_guid":"b8881ad3-48e7-431b-a542-94cd2660cfbd","_uuid":"6237093831507136636bade49c4349277ab63c6a","id":"EpyUyEiBHDX9","colab_type":"text"},"source":["Printing the accuracy score and the Confusion Matrix"]},{"cell_type":"code","metadata":{"_cell_guid":"358df9a9-dade-46b7-a9bc-dafc280a7adc","_uuid":"f436bf213e921eb5b6737fcd7eb1b4224fe34426","id":"wIYsoWtaHDX_","colab_type":"code","outputId":"16217d6c-d40f-46b8-8cc9-8c8f87650ce0","executionInfo":{"status":"ok","timestamp":1581699978652,"user_tz":-330,"elapsed":8277,"user":{"displayName":"Tushar Saraf","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBsVKflt1O4j3WrSDN4_oLhCgLTQjjyjEEi2HI8ng=s64","userId":"06289736158237069082"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["from sklearn.metrics import confusion_matrix\n","cm = confusion_matrix(y_test, y_pred)\n","print(cm)"],"execution_count":239,"outputs":[{"output_type":"stream","text":["[[1595    0]\n"," [ 405    0]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rIIYR6oHHDYK","colab_type":"code","outputId":"2051530e-51e8-4767-b626-4103cd169a12","executionInfo":{"status":"ok","timestamp":1581699978653,"user_tz":-330,"elapsed":8265,"user":{"displayName":"Tushar Saraf","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBsVKflt1O4j3WrSDN4_oLhCgLTQjjyjEEi2HI8ng=s64","userId":"06289736158237069082"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print (((cm[0][0]+cm[1][1])*100)/(len(y_test)), '% of test data about the customers leaving the bank is classified correctly')"],"execution_count":240,"outputs":[{"output_type":"stream","text":["79.75 % of test data about the customers leaving the bank is classified correctly\n"],"name":"stdout"}]}]}